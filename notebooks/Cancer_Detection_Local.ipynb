{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa10d71f",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection \n",
    "**Optimized for CPU/Local Training**\n",
    "\n",
    "This notebook is configured to run on your local machine with the dataset on C: drive.\n",
    "\n",
    "**Key Differences from Kaggle Version:**\n",
    "- CPU-optimized (no GPU/CUDA required)\n",
    "- Smaller batch sizes for memory efficiency\n",
    "- Fewer epochs for faster iteration\n",
    "- Works with local data paths\n",
    "\n",
    "**Author**: gittaqui  \n",
    "**GitHub**: https://github.com/gittaqui/WK_3_CNN_Cancer_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d362bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Force CPU usage to avoid CUDA errors\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable GPU\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'   # Reduce TensorFlow warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0, MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "# Verify CPU mode\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "print(f\"Running on: {'GPU' if tf.config.list_physical_devices('GPU') else 'CPU'}\")\n",
    "\n",
    "# Set random seeds\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"\\nâœ“ Setup complete - Running in CPU mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c5b47",
   "metadata": {},
   "source": [
    "## 1. Configuration - CPU Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - Local data on C: drive\n",
    "BASE_PATH = Path('C:/kaggle_data/cancer_detection')\n",
    "TRAIN_DIR = BASE_PATH / 'train'\n",
    "TEST_DIR = BASE_PATH / 'test'\n",
    "TRAIN_LABELS = BASE_PATH / 'train_labels.csv'\n",
    "\n",
    "# Verify paths\n",
    "print(\"Checking data paths...\")\n",
    "print(f\"Base path exists: {BASE_PATH.exists()}\")\n",
    "print(f\"Train dir exists: {TRAIN_DIR.exists()}\")\n",
    "print(f\"Test dir exists: {TEST_DIR.exists()}\")\n",
    "print(f\"Labels file exists: {TRAIN_LABELS.exists()}\")\n",
    "\n",
    "# CPU-Optimized Configuration\n",
    "CONFIG = {\n",
    "    # Image settings\n",
    "    'IMG_SIZE': 96,\n",
    "    'BATCH_SIZE': 32,  # Smaller for CPU\n",
    "    'CHANNELS': 3,\n",
    "    \n",
    "    # Training settings\n",
    "    'EPOCHS': 15,  # Fewer epochs for local testing\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'VALIDATION_SPLIT': 0.2,\n",
    "    \n",
    "    # Model settings\n",
    "    'ARCHITECTURE': 'MobileNetV2',  # Lighter model for CPU\n",
    "    'DROPOUT_RATE': 0.3,\n",
    "    'DENSE_UNITS': 128,  # Smaller for CPU\n",
    "    \n",
    "    # Augmentation\n",
    "    'USE_AUGMENTATION': True,\n",
    "    'TTA_STEPS': 3,  # Fewer TTA steps for speed\n",
    "    \n",
    "    # Optimization\n",
    "    'EARLY_STOPPING_PATIENCE': 4,\n",
    "    'REDUCE_LR_PATIENCE': 2,\n",
    "    'REDUCE_LR_FACTOR': 0.5,\n",
    "    \n",
    "    # Sampling (for quick tests)\n",
    "    'USE_SUBSET': False,  # Set True for quick testing\n",
    "    'SUBSET_SIZE': 10000,  # Use smaller dataset for testing\n",
    "}\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save directory\n",
    "SAVE_DIR = Path('D:/MS_in_AI/WK3_CNN_Detection/WK_3_CNN_Cancer_Detection/models')\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "print(f\"\\nModels will be saved to: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b5c2b",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training labels\n",
    "train_df = pd.read_csv(TRAIN_LABELS)\n",
    "print(f\"Total training samples: {len(train_df):,}\")\n",
    "\n",
    "# Use subset if configured\n",
    "if CONFIG['USE_SUBSET']:\n",
    "    print(f\"\\nUsing subset of {CONFIG['SUBSET_SIZE']:,} samples for quick testing\")\n",
    "    train_df = train_df.sample(n=CONFIG['SUBSET_SIZE'], random_state=SEED).reset_index(drop=True)\n",
    "    print(f\"Subset size: {len(train_df):,}\")\n",
    "\n",
    "# Add filename\n",
    "train_df['filename'] = train_df['id'].apply(lambda x: f'{x}.tif')\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution:\")\n",
    "class_counts = train_df['label'].value_counts().sort_index()\n",
    "print(class_counts)\n",
    "print(f\"\\nClass balance:\")\n",
    "print(train_df['label'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "class_counts.plot(kind='bar', ax=axes[0], color=['green', 'red'], alpha=0.7)\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class (0=Benign, 1=Cancer)', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(['Benign (0)', 'Cancer (1)'], rotation=0)\n",
    "for i, v in enumerate(class_counts):\n",
    "    axes[0].text(i, v + 1000, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Sample images\n",
    "sample_images = train_df.groupby('label').sample(n=3, random_state=SEED)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Sample Images by Class', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Create subplot grid for samples\n",
    "fig2, axes2 = plt.subplots(2, 3, figsize=(12, 8))\n",
    "for idx, (_, row) in enumerate(sample_images.iterrows()):\n",
    "    img_path = TRAIN_DIR / row['filename']\n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        ax = axes2[idx // 3, idx % 3]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Class: {row['label']} ({'Cancer' if row['label'] == 1 else 'Benign'})\", \n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(train_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7c746",
   "metadata": {},
   "source": [
    "## 3. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73638c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df,\n",
    "    test_size=CONFIG['VALIDATION_SPLIT'],\n",
    "    stratify=train_df['label'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_data):,}\")\n",
    "print(f\"Validation samples: {len(val_data):,}\")\n",
    "\n",
    "print(f\"\\nTraining class distribution:\")\n",
    "print(train_data['label'].value_counts().sort_index())\n",
    "print(f\"\\nValidation class distribution:\")\n",
    "print(val_data['label'].value_counts().sort_index())\n",
    "\n",
    "# Calculate class weights for imbalanced data\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_data['label']),\n",
    "    y=train_data['label']\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(f\"\\nClass weights (for balanced training):\")\n",
    "print(f\"  Class 0 (Benign): {class_weights[0]:.3f}\")\n",
    "print(f\"  Class 1 (Cancer): {class_weights[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80980f0a",
   "metadata": {},
   "source": [
    "## 4. Data Generators with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training generator with augmentation\n",
    "if CONFIG['USE_AUGMENTATION']:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        brightness_range=[0.85, 1.15]\n",
    "    )\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Validation generator (no augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory=str(TRAIN_DIR),\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_data,\n",
    "    directory=str(TRAIN_DIR),\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Training batches per epoch: {len(train_generator)}\")\n",
    "print(f\"Validation batches: {len(val_generator)}\")\n",
    "print(f\"\\nAugmentation enabled: {CONFIG['USE_AUGMENTATION']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6935035",
   "metadata": {},
   "source": [
    "## 5. Build Model - CPU Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(architecture='MobileNetV2'):\n",
    "    \"\"\"\n",
    "    Build lightweight model optimized for CPU training\n",
    "    \"\"\"\n",
    "    input_shape = (CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'], CONFIG['CHANNELS'])\n",
    "    \n",
    "    # Choose base model (CPU-friendly)\n",
    "    if architecture == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=input_shape,\n",
    "            pooling='avg'\n",
    "        )\n",
    "        preprocess_func = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    elif architecture == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=input_shape,\n",
    "            pooling='avg'\n",
    "        )\n",
    "        preprocess_func = tf.keras.applications.efficientnet.preprocess_input\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")\n",
    "    \n",
    "    # Fine-tune last layers\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-15]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = preprocess_func(inputs)\n",
    "    x = base_model(x, training=True)\n",
    "    x = layers.Dropout(CONFIG['DROPOUT_RATE'])(x)\n",
    "    x = layers.Dense(CONFIG['DENSE_UNITS'], activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(CONFIG['DROPOUT_RATE'] / 2)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(CONFIG['LEARNING_RATE']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "print(\"Building model...\")\n",
    "model = build_model(CONFIG['ARCHITECTURE'])\n",
    "\n",
    "print(f\"\\nModel: {CONFIG['ARCHITECTURE']}\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {model.count_params() - trainable_params:,}\")\n",
    "\n",
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc0193",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdaef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=CONFIG['REDUCE_LR_FACTOR'],\n",
    "        patience=CONFIG['REDUCE_LR_PATIENCE'],\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        str(SAVE_DIR / 'best_model_local.h5'),\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.CSVLogger(\n",
    "        str(SAVE_DIR / 'training_log.csv'),\n",
    "        append=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Running on: CPU\")\n",
    "print(f\"Epochs: {CONFIG['EPOCHS']}\")\n",
    "print(f\"Batch size: {CONFIG['BATCH_SIZE']}\")\n",
    "print(f\"Training samples: {len(train_data):,}\")\n",
    "print(f\"Validation samples: {len(val_data):,}\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=CONFIG['EPOCHS'],\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a02f37",
   "metadata": {},
   "source": [
    "## 7. Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_title('Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Train Acc', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)\n",
    "axes[1].set_title('Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "axes[2].plot(history.history['auc'], label='Train AUC', linewidth=2)\n",
    "axes[2].plot(history.history['val_auc'], label='Val AUC', linewidth=2)\n",
    "axes[2].set_title('AUC Score Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('AUC', fontsize=12)\n",
    "axes[2].legend(fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print best metrics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Validation Loss: {min(history.history['val_loss']):.4f}\")\n",
    "print(f\"Best Validation Accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "print(f\"Best Validation AUC: {max(history.history['val_auc']):.4f}\")\n",
    "print(f\"\\nFinal Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Training AUC: {history.history['auc'][-1]:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32b069",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "print(\"Generating predictions on validation set...\")\n",
    "val_predictions = model.predict(val_generator, verbose=1)\n",
    "val_pred_proba = val_predictions.flatten()\n",
    "val_pred_binary = (val_pred_proba > 0.5).astype(int)\n",
    "val_true = val_data['label'].values\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "val_accuracy = accuracy_score(val_true, val_pred_binary)\n",
    "val_precision = precision_score(val_true, val_pred_binary)\n",
    "val_recall = recall_score(val_true, val_pred_binary)\n",
    "val_f1 = f1_score(val_true, val_pred_binary)\n",
    "val_auc = roc_auc_score(val_true, val_pred_proba)\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {val_accuracy:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall:    {val_recall:.4f}\")\n",
    "print(f\"F1 Score:  {val_f1:.4f}\")\n",
    "print(f\"AUC Score: {val_auc:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_true, val_pred_binary)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], \n",
    "            xticklabels=['Benign', 'Cancer'],\n",
    "            yticklabels=['Benign', 'Cancer'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('True', fontsize=12)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(val_true, val_pred_proba)\n",
    "axes[1].plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {val_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'evaluation_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(val_true, val_pred_binary, \n",
    "                          target_names=['Benign (0)', 'Cancer (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78cced",
   "metadata": {},
   "source": [
    "## 9. Generate Test Predictions with TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_files = list(TEST_DIR.glob('*.tif'))\n",
    "test_df = pd.DataFrame({\n",
    "    'id': [f.stem for f in test_files],\n",
    "    'filename': [f.name for f in test_files]\n",
    "})\n",
    "\n",
    "print(f\"Test samples: {len(test_df):,}\")\n",
    "\n",
    "# Test-Time Augmentation\n",
    "def predict_with_tta(model, test_df, n_tta=3):\n",
    "    \"\"\"\n",
    "    Predictions with Test-Time Augmentation\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for tta_idx in tqdm(range(n_tta), desc=\"TTA Progress\"):\n",
    "        if tta_idx == 0:\n",
    "            # No augmentation\n",
    "            datagen = ImageDataGenerator(rescale=1./255)\n",
    "        else:\n",
    "            # With augmentation\n",
    "            datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=20,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True\n",
    "            )\n",
    "        \n",
    "        test_gen = datagen.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=str(TEST_DIR),\n",
    "            x_col='filename',\n",
    "            y_col=None,\n",
    "            target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
    "            batch_size=CONFIG['BATCH_SIZE'],\n",
    "            class_mode=None,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        preds = model.predict(test_gen, verbose=0)\n",
    "        all_predictions.append(preds)\n",
    "    \n",
    "    # Average predictions\n",
    "    final_predictions = np.mean(all_predictions, axis=0)\n",
    "    return final_predictions.flatten()\n",
    "\n",
    "print(\"\\nGenerating test predictions with TTA...\")\n",
    "test_predictions = predict_with_tta(model, test_df, n_tta=CONFIG['TTA_STEPS'])\n",
    "\n",
    "print(f\"\\nPredictions complete!\")\n",
    "print(f\"Shape: {test_predictions.shape}\")\n",
    "print(f\"Range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "print(f\"Mean: {test_predictions.mean():.4f}\")\n",
    "print(f\"Median: {np.median(test_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444a07e",
   "metadata": {},
   "source": [
    "## 10. Create Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'label': test_predictions\n",
    "})\n",
    "\n",
    "# Sort by id\n",
    "submission = submission.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "# Save to project directory\n",
    "submission_path = Path('D:/MS_in_AI/WK3_CNN_Detection/WK_3_CNN_Cancer_Detection/submission.csv')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(\"âœ“ Submission file created!\")\n",
    "print(f\"\\nSaved to: {submission_path}\")\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "display(submission.head(10))\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Min:    {submission['label'].min():.4f}\")\n",
    "print(f\"Max:    {submission['label'].max():.4f}\")\n",
    "print(f\"Mean:   {submission['label'].mean():.4f}\")\n",
    "print(f\"Median: {submission['label'].median():.4f}\")\n",
    "print(f\"Std:    {submission['label'].std():.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(submission['label'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0.5, color='red', linestyle='--', linewidth=2, label='Threshold=0.5')\n",
    "axes[0].set_title('Distribution of Predictions', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted Probability', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Binary predictions\n",
    "binary_preds = (submission['label'] > 0.5).astype(int)\n",
    "binary_counts = binary_preds.value_counts().sort_index()\n",
    "binary_counts.plot(kind='bar', ax=axes[1], color=['green', 'red'], alpha=0.7)\n",
    "axes[1].set_title('Predicted Classes (threshold=0.5)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_xticklabels(['Benign (0)', 'Cancer (1)'], rotation=0)\n",
    "for i, v in enumerate(binary_counts):\n",
    "    axes[1].text(i, v + 500, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'submission_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL DONE! READY TO SUBMIT TO KAGGLE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSubmission file: {submission_path}\")\n",
    "print(f\"Model file: {SAVE_DIR / 'best_model_local.h5'}\")\n",
    "print(f\"\\nUpload submission.csv to:\")\n",
    "print(f\"https://www.kaggle.com/c/histopathologic-cancer-detection/submit\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691462a0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Configuration:\n",
    "- **Architecture**: MobileNetV2 (CPU-optimized)\n",
    "- **Training**: Local machine (CPU)\n",
    "- **Data**: Full dataset from C: drive\n",
    "- **Augmentation**: Rotation, flips, shifts, zoom\n",
    "- **TTA**: 3 augmentation steps\n",
    "\n",
    "### Next Steps:\n",
    "1. âœ… Model trained and evaluated\n",
    "2. âœ… Submission file created\n",
    "3. ðŸ“¤ Upload `submission.csv` to Kaggle\n",
    "4. ðŸ“Š Check leaderboard score\n",
    "5. ðŸ“¸ Take screenshot of leaderboard\n",
    "\n",
    "### To Improve Score:\n",
    "- Upload and run the Kaggle competition notebook (GPU accelerated)\n",
    "- Use EfficientNetB3/B4 instead of MobileNetV2\n",
    "- Train for more epochs (25-30)\n",
    "- Increase TTA steps to 5-10\n",
    "- Train multiple folds and ensemble\n",
    "\n",
    "**Good luck! ðŸŽ¯**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
